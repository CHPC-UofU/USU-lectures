{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install dask-jobqueue:\n",
    "conda install dask-jobqueue -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(cores=8,processes=4,project=\"notchpeak-shared-short\",queue=\"notchpeak-shared-short\",memory='8g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will define a Dask execution object with 4 processes, each using 2 cores. Each job is submitted with one task, and 8 cores per task. The above will just define the job, the below will submit one such jobs, each using the 8 cores. Note that notchpeak-shared-short allows max 2 running jobs per user, so, if we're running this notebook in notchpeak-shared-short via Open OnDemand we can only use one more job (worker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "from dask import delayed\n",
    "\n",
    "cluster.start_workers(1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what job script the Dask uses, which is useful in figuring out the SLURM task / CPU usage mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p notchpeak-shared-short\n",
      "#SBATCH -A notchpeak-shared-short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --mem=8G\n",
      "#SBATCH -t 00:30:00\n",
      "JOB_ID=${SLURM_JOB_ID%;*}\n",
      "\n",
      "\n",
      "\n",
      "/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/bin/python -m distributed.cli.dask_worker tcp://10.242.75.81:39045 --nthreads 2 --nprocs 4 --memory-limit 2.00GB --name dask-worker--${JOB_ID}-- --death-timeout 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.242.75.81:39045</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.242.75.81:8787/status' target='_blank'>http://10.242.75.81:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.242.75.81:39045' processes=4 threads=8, memory=8.00 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the same embarrassingly parallel example, but using the SLURM job that Dask started. Note that the code is the same as in the local Dask run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def costly_simulation(list_param):\n",
    "    time.sleep(random.random())\n",
    "    return sum(list_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_a</th>\n",
       "      <th>param_b</th>\n",
       "      <th>param_c</th>\n",
       "      <th>param_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.442653</td>\n",
       "      <td>0.474941</td>\n",
       "      <td>0.418876</td>\n",
       "      <td>0.273237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.357813</td>\n",
       "      <td>0.531603</td>\n",
       "      <td>0.656388</td>\n",
       "      <td>0.311080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534062</td>\n",
       "      <td>0.904749</td>\n",
       "      <td>0.743362</td>\n",
       "      <td>0.367175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>0.763310</td>\n",
       "      <td>0.606051</td>\n",
       "      <td>0.872185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349374</td>\n",
       "      <td>0.107803</td>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.179712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_a   param_b   param_c   param_d\n",
       "0  0.442653  0.474941  0.418876  0.273237\n",
       "1  0.357813  0.531603  0.656388  0.311080\n",
       "2  0.534062  0.904749  0.743362  0.367175\n",
       "3  0.281190  0.763310  0.606051  0.872185\n",
       "4  0.349374  0.107803  0.064185  0.179712"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_params = pd.DataFrame(np.random.random(size=(500, 4)),\n",
    "                            columns=['param_a', 'param_b', 'param_c', 'param_d'])\n",
    "input_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "lazy_results = []\n",
    "\n",
    "for parameters in input_params.values:\n",
    "    lazy_result = dask.delayed(costly_simulation)(parameters)\n",
    "    lazy_results.append(lazy_result)\n",
    "\n",
    "futures = dask.persist(*lazy_results)  # trigger computation in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.47 s, sys: 430 ms, total: 2.9 s\n",
      "Wall time: 29.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.6097077549704961,\n",
       " 1.8568845125651061,\n",
       " 2.5493481296713503,\n",
       " 2.5227364817882205,\n",
       " 0.7010738471783476)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time results = dask.compute(*futures)\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are done with using Dask, we cancel the job that runs the Dask workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/lib/python3.7/site-packages/distributed/utils.py\", line 666, in log_errors\n",
      "    yield\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 1276, in _close\n",
      "    await gen.with_timeout(timedelta(seconds=2), list(coroutines))\n",
      "concurrent.futures._base.CancelledError\n",
      "distributed.utils - ERROR - \n",
      "Traceback (most recent call last):\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/lib/python3.7/site-packages/distributed/utils.py\", line 666, in log_errors\n",
      "    yield\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 1005, in _reconnect\n",
      "    await self._close()\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u0101881/software/pkg/miniconda3/lib/python3.7/site-packages/distributed/client.py\", line 1276, in _close\n",
      "    await gen.with_timeout(timedelta(seconds=2), list(coroutines))\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
